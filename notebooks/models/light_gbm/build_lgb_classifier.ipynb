{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST - TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = 'data/processed/'\n",
    "SEED = 47\n",
    "NITER = 100\n",
    "CV = 5\n",
    "SCORE = 'roc_auc'\n",
    "handlingnull = False\n",
    "NJOBS = -1\n",
    "USEGPU = False\n",
    "NCLASS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_pickle(DATAPATH+'X.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212665, 1205)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_pickle(DATAPATH+'y.pkl')[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = pd.read_pickle('data/features/campaign_quarter_001.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital = pd.read_pickle('data/features/digital_features_period_001.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcc = pd.read_pickle('data/features/X_rcc_features_quarter_001.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcc.drop(['id_persona', 'codmes'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feateng = pd.read_pickle('data/features/featureseng_train_001.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "woe = pd.read_pickle('data/features/X_woe_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.join(campaign).join(rcc).join(digital).join(feateng).join(woe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212665, 1800)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_eng = np.load('data/train_test/features_selected.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features[features_eng]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_features = train_features.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212665, 800)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a DMatrix and handling Null values\n",
    "if handlingnull:\n",
    "    #train_features[np.isnan(train_features)] = -9999\n",
    "    lgb_train = lgb.Dataset(train_features.values, train_labels.values, missing=-9999)\n",
    "else:\n",
    "    lgb_train = lgb.Dataset(train_features.values, train_labels.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== General Parameters ======= #\n",
    "\n",
    "# Select the type of model to run at each iteration. gbtree or gblinear.\n",
    "boosting = 'gbdt'\n",
    "\n",
    "\n",
    "# ======== Booster Parameters ======== # \n",
    "\n",
    "# Analogous to learning rate in GBM. \n",
    "# Typical final values to be used: 0.01-0.2\n",
    "eta = 0.01 \n",
    "\n",
    "\n",
    "# A node is split only when the resulting split gives a positive reduction in the loss function. \n",
    "# Gamma specifies the minimum loss reduction required to make a split.\n",
    "gamma = [i/10.0 for i in range(0,5)]\n",
    "\n",
    "\n",
    "# Control the balance of positive and negative weights, useful for unbalanced classes. \n",
    "# A typical value to consider: sum(negative instances) / sum(positive instances)scale_pos_weight = 1\n",
    "scale_pos_weight = (len(train_labels.target) - sum(train_labels.target))/sum(train_labels.target)\n",
    "\n",
    "\n",
    "# Learning Task Parameters\n",
    "# This defines the loss function to be minimized. See documentation\n",
    "# -  options: regression, regression_l1, huber, fair, poisson, quantile, \n",
    "# mape, gamma, tweedie, binary, multiclass, multiclassova, cross_entropy, cross_entropy_lambda,\n",
    "# lambdarank, aliases: objective_type, app, application\n",
    "objective  = 'binary'\n",
    "\n",
    "\n",
    "# The metric to be used for validation data.\n",
    "# - rmse, root square loss, aliases: root_mean_squared_error, l2_root\n",
    "# - quantile, Quantile regression\n",
    "# - mape, MAPE loss, aliases: mean_absolute_percentage_error\n",
    "# - huber, Huber loss\n",
    "# - fair, Fair loss\n",
    "# - poisson, negative log-likelihood for Poisson regression\n",
    "# - gamma, negative log-likelihood for Gamma regression\n",
    "# - gamma_deviance, residual deviance for Gamma regression\n",
    "# - tweedie, negative log-likelihood for Tweedie regression\n",
    "# - ndcg, NDCG, aliases: lambdarank\n",
    "# - map, MAP, aliases: mean_average_precision\n",
    "# - auc, AUC\n",
    "# - binary_logloss, log loss, aliases: binary\n",
    "metric = 'auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = np.load('output/models/bayesianoptcv_gbm_classifier_bestparams_d2019-11-28.npy',allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param['max_depth'] = int(np.round(model_param['max_depth'],0))\n",
    "model_param['min_child_weight'] = int(np.round(model_param['min_child_weight'],0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param['num_leaves'] = int(np.round(model_param['num_leaves'],0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param['seed'] = SEED\n",
    "model_param['booster'] = boosting\n",
    "model_param['objective'] = objective\n",
    "model_param['scale_pos_weight'] = scale_pos_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param['num_threads'] = NJOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.8327365806346091,\n",
       " 'feature_fraction': 0.8881760200078465,\n",
       " 'max_depth': 13,\n",
       " 'min_child_weight': 30,\n",
       " 'min_split_gain': 0.004145814603445978,\n",
       " 'num_leaves': 99,\n",
       " 'n_estimators': 344,\n",
       " 'seed': 47,\n",
       " 'booster': 'gbdt',\n",
       " 'objective': 'binary',\n",
       " 'scale_pos_weight': 9.227229008367798,\n",
       " 'num_threads': -1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmodel = lgb.train(model_param, lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7fd8decbc128>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmodel.save_model('output/models/lgb_002.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/xgb_004.features', train_features.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xgboost (env)",
   "language": "python",
   "name": "xgboostenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
