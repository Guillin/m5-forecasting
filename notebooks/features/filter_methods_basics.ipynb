{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Methods - Basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = '../../data/train_test'\n",
    "OUTPUT_PATH = '../../data/features'\n",
    "OUTPUT_FILE_NAME = 'filter_basic_features_selected_v001'\n",
    "N_SPLITS = 3 # numbers of folds\n",
    "DAY_COL = 'd'\n",
    "DATE_COL = \"date\"\n",
    "D_THRESH = 1941 - int(365 * 2) # he only left 2 years of training data, from 2014-05-23 to 2016-05-24\n",
    "DAYS_PRED = 28\n",
    "SEED = 87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=False):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    int_columns = df.select_dtypes(include=[\"int\"]).columns\n",
    "    float_columns = df.select_dtypes(include=[\"float\"]).columns\n",
    "\n",
    "    for col in int_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Santander customer satisfaction dataset from Kaggle\n",
    "\n",
    "X_train = pd.read_pickle(f'{INPUT_PATH}/X_train.pkl').pipe(reduce_mem_usage)\n",
    "X_test  = pd.read_pickle(f'{INPUT_PATH}/X_val.pkl').pipe(reduce_mem_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20580750, 124), (853720, 124))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.groupby(['item_id', 'store_id']).apply(lambda x: pd.DataFrame.sample(x, frac=.3, random_state=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.groupby(['item_id', 'store_id']).apply(lambda x: pd.DataFrame.sample(x, frac=.3, random_state=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6158980, 124), (243920, 124))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.select_dtypes(exclude=['datetime','object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_init = X_train[features].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6158980, 124), (243920, 124))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove constant features\n",
    "constant_features = [\n",
    "    feat for feat in X_train[features].columns if X_train[feat].std() == 0\n",
    "]\n",
    "\n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.select_dtypes(exclude=['datetime','object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/statenv/lib/python3.8/site-packages/sklearn/feature_selection/_variance_threshold.py:77: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  self.variances_ = np.nanvar(X, axis=0)\n",
      "/opt/anaconda3/envs/statenv/lib/python3.8/site-packages/sklearn/feature_selection/_variance_threshold.py:88: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (self.variances_ <= self.threshold)):\n",
      "/opt/anaconda3/envs/statenv/lib/python3.8/site-packages/sklearn/feature_selection/_variance_threshold.py:99: RuntimeWarning: invalid value encountered in greater\n",
      "  return self.variances_ > self.threshold\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove quasi-constant features\n",
    "sel = VarianceThreshold(\n",
    "    threshold=0.01)  # 0.1 indicates 99% of observations approximately\n",
    "\n",
    "sel.fit(X_train[features])  # fit finds the features with low variance\n",
    "\n",
    "sum(sel.get_support()) # how many not quasi-constant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = X_train[features].columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6158980, 117), (243920, 117))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can then remove the features like this\n",
    "X_train = X_train[features_to_keep]\n",
    "X_test  = X_test[features_to_keep]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# check for duplicated features in the training set\n",
    "duplicated_feat = []\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    if i % 10 == 0:  # this helps me understand how the loop is going\n",
    "        print(i)\n",
    "\n",
    "    col_1 = X_train.columns[i]\n",
    "\n",
    "    for col_2 in X_train.columns[i + 1:]:\n",
    "        if X_train[col_1].equals(X_train[col_2]):\n",
    "            duplicated_feat.append(col_2)\n",
    "            \n",
    "len(duplicated_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features_init) - X_train.shape[1], \" were removed. The number of final features is \", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{OUTPUT_PATH}/{OUTPUT_FILE_NAME}.npy',features_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = np.load(f'{OUTPUT_PATH}/{OUTPUT_FILE_NAME}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'wm_yr_wk',\n",
       "       'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX', 'snap_WI',\n",
       "       'sell_price', 'demand_smoothed_shift_t28',\n",
       "       'demand_smoothed_shift_t29', 'demand_smoothed_shift_t30',\n",
       "       'demand_smoothed_shift_t31', 'demand_smoothed_shift_t32',\n",
       "       'demand_smoothed_shift_t33', 'demand_smoothed_rolling_std_t5',\n",
       "       'demand_smoothed_rolling_std_t10',\n",
       "       'demand_smoothed_rolling_std_t30',\n",
       "       'demand_smoothed_rolling_std_t70',\n",
       "       'demand_smoothed_rolling_std_t90',\n",
       "       'demand_smoothed_rolling_std_t120',\n",
       "       'demand_smoothed_rolling_std_t180',\n",
       "       'demand_smoothed_rolling_mean_t5',\n",
       "       'demand_smoothed_rolling_mean_t10',\n",
       "       'demand_smoothed_rolling_mean_t30',\n",
       "       'demand_smoothed_rolling_mean_t70',\n",
       "       'demand_smoothed_rolling_mean_t90',\n",
       "       'demand_smoothed_rolling_mean_t120',\n",
       "       'demand_smoothed_rolling_mean_t180',\n",
       "       'demand_smoothed_rolling_acum_mean_t5',\n",
       "       'demand_smoothed_rolling_acum_mean_t10',\n",
       "       'demand_smoothed_rolling_acum_mean_t30',\n",
       "       'demand_smoothed_rolling_acum_mean_t70',\n",
       "       'demand_smoothed_rolling_acum_mean_t90',\n",
       "       'demand_smoothed_rolling_acum_mean_t120',\n",
       "       'demand_smoothed_rolling_acum_mean_t180',\n",
       "       'demand_smoothed_rolling_min_t5',\n",
       "       'demand_smoothed_rolling_min_t10',\n",
       "       'demand_smoothed_rolling_min_t30',\n",
       "       'demand_smoothed_rolling_min_t70',\n",
       "       'demand_smoothed_rolling_min_t90',\n",
       "       'demand_smoothed_rolling_min_t120',\n",
       "       'demand_smoothed_rolling_min_t180',\n",
       "       'demand_smoothed_rolling_max_t5',\n",
       "       'demand_smoothed_rolling_max_t10',\n",
       "       'demand_smoothed_rolling_max_t30',\n",
       "       'demand_smoothed_rolling_max_t70',\n",
       "       'demand_smoothed_rolling_max_t90',\n",
       "       'demand_smoothed_rolling_max_t120',\n",
       "       'demand_smoothed_rolling_max_t180',\n",
       "       'demand_smoothed_rolling_skew_t5',\n",
       "       'demand_smoothed_rolling_skew_t10',\n",
       "       'demand_smoothed_rolling_skew_t30',\n",
       "       'demand_smoothed_rolling_skew_t70',\n",
       "       'demand_smoothed_rolling_skew_t90',\n",
       "       'demand_smoothed_rolling_skew_t120',\n",
       "       'demand_smoothed_rolling_skew_t180',\n",
       "       'demand_smoothed_rolling_kurt_t5',\n",
       "       'demand_smoothed_rolling_kurt_t10',\n",
       "       'demand_smoothed_rolling_kurt_t30',\n",
       "       'demand_smoothed_rolling_kurt_t70',\n",
       "       'demand_smoothed_rolling_kurt_t90',\n",
       "       'demand_smoothed_rolling_kurt_t120',\n",
       "       'demand_smoothed_rolling_kurt_t180',\n",
       "       'demand_smoothed_rolling_q10_t10',\n",
       "       'demand_smoothed_rolling_q10_t50',\n",
       "       'demand_smoothed_rolling_q10_t100',\n",
       "       'demand_smoothed_rolling_q10_t180',\n",
       "       'demand_smoothed_rolling_q10_t360',\n",
       "       'demand_smoothed_rolling_q50_t10',\n",
       "       'demand_smoothed_rolling_q50_t50',\n",
       "       'demand_smoothed_rolling_q50_t100',\n",
       "       'demand_smoothed_rolling_q50_t180',\n",
       "       'demand_smoothed_rolling_q50_t360',\n",
       "       'demand_smoothed_rolling_q90_t10',\n",
       "       'demand_smoothed_rolling_q90_t50',\n",
       "       'demand_smoothed_rolling_q90_t100',\n",
       "       'demand_smoothed_rolling_q90_t180',\n",
       "       'demand_smoothed_rolling_q90_t360', 'demand_smoothed_diff_1',\n",
       "       'demand_smoothed_diff_3', 'demand_smoothed_diff_7',\n",
       "       'demand_smoothed_diff_30', 'demand_smoothed_diff_90',\n",
       "       'demand_smoothed_diff_180', 'demand_smoothed_diff_360',\n",
       "       'demand_smoothed_pct_change_1', 'demand_smoothed_pct_change_3',\n",
       "       'demand_smoothed_pct_change_7', 'demand_smoothed_pct_change_30',\n",
       "       'demand_smoothed_pct_change_90', 'demand_smoothed_pct_change_180',\n",
       "       'demand_smoothed_pct_change_360', 'shift_price_t1',\n",
       "       'rolling_price_std_t30', 'price_pct_change_p1',\n",
       "       'price_pct_change_p3', 'price_pct_change_p7',\n",
       "       'price_pct_change_p30', 'price_pct_change_p90',\n",
       "       'price_pct_change_p180', 'price_pct_change_p365', 'price_diff_p7',\n",
       "       'price_diff_p30', 'price_diff_p90', 'price_diff_p180',\n",
       "       'price_diff_p365', 'year', 'quarter', 'month', 'week', 'day',\n",
       "       'dayofweek', 'is_weekend'], dtype='<U38')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statenv",
   "language": "python",
   "name": "statenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "834px",
    "left": "0px",
    "right": "20px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
