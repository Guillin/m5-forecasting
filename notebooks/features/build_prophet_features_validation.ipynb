{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import Series\n",
    "from datetime import datetime\n",
    "from ipywidgets import IntProgress\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import pickle\n",
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from fbprophet import Prophet\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = '../../data/train_test'\n",
    "OUTPUT_PATH = '../../data/train_test'\n",
    "OUTPUT_NAME = 'submission_013'\n",
    "DAYS_PRED = 28\n",
    "METRIC = 'rmse'\n",
    "cfg_prophet = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score a model, return None on failure\n",
    "def run_prophet(data, period=DAYS_PRED):\n",
    "        \n",
    "    \n",
    "    # holiday\n",
    "    calendar = pd.read_csv(f'../../data/raw/calendar.csv')\n",
    "    holidays = calendar[calendar.event_name_1.isnull()!=True][['date','event_name_1']]\n",
    "    holidays.columns = ['ds','holiday']\n",
    "    \n",
    "    item_id = data.item_id.unique()[0]\n",
    "    store_id = data.store_id.unique()[0]\n",
    "    \n",
    "    cfg_prophet = dict()\n",
    "    cfg_prophet['yearly_seasonality'] = False\n",
    "    cfg_prophet['daily_seasonality'] = False\n",
    "    cfg_prophet['weekly_seasonality'] = False\n",
    "    cfg_prophet['seasonality_prior_scale'] = 0.1\n",
    "    cfg_prophet['holidays'] = holidays\n",
    "   \n",
    "    m = Prophet(**cfg_prophet).add_seasonality(\n",
    "        name='monthly', period=30.5, fourier_order=12).add_seasonality(\n",
    "        name='weekly', period=7, fourier_order=10).add_seasonality(\n",
    "        name='yearly', period=365.25, fourier_order=12).add_seasonality(\n",
    "        name='quarterly', period=365.25/4, fourier_order=5, prior_scale=0.1)\n",
    "    \n",
    "    \n",
    "\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    with catch_warnings():\n",
    "        filterwarnings(\"ignore\")\n",
    "\n",
    "        m.fit(data[['ds','y']])\n",
    "        future = m.make_future_dataframe(periods=period,include_history=True)\n",
    "\n",
    "        forecast = m.predict(future)\n",
    "        \n",
    "        forecast['item_id'] = item_id\n",
    "        forecast['store_id'] = store_id\n",
    "    \n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vector = pickle.load(open( f'{INPUT_PATH}/X_train.pkl', \"rb\" )) # It loads a vector with the folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_vector = pickle.load(open( f'{INPUT_PATH}/Y_train.pkl', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vector = pickle.load(open( f'{INPUT_PATH}/X_val.pkl', \"rb\" )) # It loads a vector with the folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_vector = pickle.load(open( f'{INPUT_PATH}/Y_val.pkl', \"rb\" )) # It loads a vector with the folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv(f'../../data/raw/calendar.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN MODEL AND MAKE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    " 'trend',\n",
    "  'monthly',\n",
    " 'quarterly',\n",
    " 'weekly',\n",
    " 'yearly',\n",
    " 'multiplicative_terms',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(len(X_train_vector)):\n",
    "    print(f\"\\n----- Fold: ({fold + 1} / {len(X_train_vector)}) -----\\n\")\n",
    "    train = X_train_vector[fold].join(Y_train_vector[fold])\n",
    "    val = X_val_vector[fold]\n",
    "    \n",
    "    # sorting\n",
    "    train.sort_values(['item_id','store_id','date'], inplace=True, ascending=True)\n",
    "    val.sort_values(['item_id','store_id','date'], inplace=True, ascending=True)\n",
    "    \n",
    "    \n",
    "    forecast_df = pd.DataFrame()\n",
    "    STEP=547\n",
    "    init = 0\n",
    "    train_vector = []\n",
    "\n",
    "    for n in range(1,30490+1):\n",
    "        end = STEP*n\n",
    "        ts = train.iloc[init:end, [0,3,38,39]]\n",
    "        ts.columns = ['item_id', 'store_id', 'ds','y']\n",
    "        \n",
    "        train_vector.append(ts)\n",
    "        init+=STEP\n",
    "        \n",
    "        \n",
    "        \n",
    "    p = Pool(cpu_count())\n",
    "    predictions = list(tqdm_notebook(p.imap(run_prophet, train_vector), total=len(train_vector)))\n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "    for pred in predictions:\n",
    "        forecast_df = forecast_df.append(pred[features + ['item_id','store_id','ds']])\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Unimos dataset train y validation con los valores de forecast y reeamplazamos en el vector principal\n",
    "    train = pd.merge(train, forecast_df[features + ['ds']], how='inner',\n",
    "                     left_on=['item_id','store_id','date'], right_on=['item_id','store_id','ds'])\n",
    "    \n",
    "    val = pd.merge(val, forecast_df[features + ['ds']], how='inner',\n",
    "                     left_on=['item_id','store_id','date'], right_on=['item_id','store_id','ds'])\n",
    "        \n",
    "    train.drop(['ds','demand_smoothed'],axis=1, inplace=True)\n",
    "    val.drop(['ds'],axis=1, inplace=True)\n",
    "    \n",
    "    X_train_vector[fold] = train\n",
    "    X_val_vector[fold] = val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prophetenv",
   "language": "python",
   "name": "prophetenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
