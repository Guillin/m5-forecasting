{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate roc-auc or mse\n",
    "\n",
    "This procedure works as follows:\n",
    "\n",
    "- First, it builds one decision tree per feature, to predict the target\n",
    "- Second, it makes predictions using the decision tree and the mentioned feature\n",
    "- Third, it ranks the features according to the machine learning metric (roc-auc or mse)\n",
    "- It selects the highest ranked features\n",
    "\n",
    "I will demonstrate how to select features based on univariate roc-auc or univariate mse information on a regression and classification problem. For classification I will use the Paribas claims dataset from Kaggle. For regression, the House Price dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from ipywidgets import IntProgress\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = '../../data/train_test'\n",
    "OUTPUT_PATH = '../../data/features'\n",
    "INPUT_FILE_NAME = 'filter_features_correlation_v008'\n",
    "OUTPUT_FILE_NAME = 'filter_univariate_rocauc_mse_v008'\n",
    "SEED = 47\n",
    "CUTOFF = 0.9\n",
    "TOP_FEATURES = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=False):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    int_columns = df.select_dtypes(include=[\"int\"]).columns\n",
    "    float_columns = df.select_dtypes(include=[\"float\"]).columns\n",
    "\n",
    "    for col in int_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tree_regressor(feature):\n",
    "    clf = DecisionTreeRegressor()\n",
    "    clf.fit(X_train[feature].to_frame(), y_train)\n",
    "    y_scored = clf.predict(X_test[feature].to_frame())\n",
    "    \n",
    "    return mean_squared_error(y_test, y_scored)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tree_classification(feature):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train[feature].to_frame(), y_train)\n",
    "    y_scored = clf.predict_proba(X_test[feature].to_frame())\n",
    "    \n",
    "    return roc_auc_score(y_test, y_scored[:, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "X_train = pd.read_pickle(f'{INPUT_PATH}/X_train.pkl').pipe(reduce_mem_usage)\n",
    "y_train = pd.read_pickle(f'{INPUT_PATH}/Y_train.pkl')\n",
    "X_test = pd.read_pickle(f'{INPUT_PATH}/X_val.pkl').pipe(reduce_mem_usage)\n",
    "y_test = pd.read_pickle(f'{INPUT_PATH}/Y_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load(f'{OUTPUT_PATH}/{INPUT_FILE_NAME}.npy').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['target'] = y_train.values\n",
    "X_test['target'] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_init = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.groupby(['item_id', 'store_id']).apply(lambda x: pd.DataFrame.sample(x, frac=.3, random_state=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.groupby(['item_id', 'store_id']).apply(lambda x: pd.DataFrame.sample(x, frac=.3, random_state=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECT NUMERIC FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catfeatures = set(['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'month', 'week', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess whether they are correlated with other features\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(X_train.select_dtypes(include=numerics).columns)\n",
    "X_train = X_train[numerical_vars]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to build a tree, make predictions and get the roc-auc\n",
    "# for each feature of the train set\n",
    "features = list(X_train.columns)\n",
    "roc_values = []\n",
    "\n",
    "tic = datetime.now()\n",
    "p = Pool(cpu_count())\n",
    "roc_values = list(tqdm_notebook(p.imap(run_tree_classification, features), total=len(features)))\n",
    "p.close()\n",
    "p.join()\n",
    "toc = datetime.now()\n",
    "print(\"Total time \" ,(toc - tic).seconds/60, \" min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add the variable names and order it for clearer visualisation\n",
    "roc_values = pd.Series(roc_values)\n",
    "roc_values.index = X_train.columns\n",
    "roc_values.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now let's plot\n",
    "roc_values.sort_values(ascending=False).plot.bar(figsize=(20, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a roc auc value of 0.5 indicates random decision\n",
    "# let's check how many features show a roc-auc value\n",
    "# higher than random\n",
    "\n",
    "len(roc_values[roc_values > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = list(roc_values[roc_values > 0.5].iloc[:TOP_FEATURES].reset_index()['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features) - len(features_final), \" were removed. The number of final features is \", len(features_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final features\n",
    "np.save(f'{OUTPUT_PATH}/{OUTPUT_FILE_NAME}.npy',features_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can of course tune the parameters of the Decision Tree and get better predictions. I leave this to you. But remember that the key here is not to make ultra predictive Decision Trees, rather to use them to screen quickly for important features. So I would recommend you don't spend too much time tuning. Doing cross validation with sklearn should be very straight forward  to get a more accurate measure of the roc-auc per feature.\n",
    "\n",
    "Once again, where we put the cut-off to select features is a bit arbitrary, other than > 0.5. It will be up to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to build a tree, make predictions and get the mse\n",
    "# for each feature of the train set\n",
    "features = list(X_train.columns)\n",
    "mse_values = []\n",
    "\n",
    "tic = datetime.now()\n",
    "p = Pool(cpu_count())\n",
    "mse_values = list(tqdm_notebook(p.imap(run_tree_regressor, features), total=len(features)))\n",
    "p.close()\n",
    "p.join()\n",
    "toc = datetime.now()\n",
    "print(\"Total time \" ,(toc - tic).seconds/60, \" min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's add the variable names and order it for clearer visualisation\n",
    "mse_values = pd.Series(mse_values)\n",
    "mse_values.index = X_train.columns\n",
    "mse_values.sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_values.sort_values(ascending=True).iloc[:TOP_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_values.sort_values(ascending=False).plot.bar(figsize=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = list(mse_values.sort_values(ascending=True).iloc[:TOP_FEATURES].reset_index()['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features) - len(features_final), \" were removed. The number of final features is \", len(features_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final features\n",
    "np.save(f'{OUTPUT_PATH}/{OUTPUT_FILE_NAME}.npy',features_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that for regression, the smaller the mse, the better the model performance is. So in this case, we need to select from the right to the left.\n",
    "\n",
    "For the mse, where to put the cut-off is arbitrary as well. It depends on how many features you would like to end up with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do use this method in my projects, particularly when I have an enormous amount of features and I need to start reducing the feature space quickly.\n",
    "\n",
    "You can see an example use case in [my talk at pydata London](https://www.youtube.com/watch?v=UHtAjLYgDQ4)\n",
    "\n",
    "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
